{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "sys.path.append(\"/home/pervinco/BKAI_MetaPolyp\")\n",
    "\n",
    "import cv2\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from data.batch_preprocess import *\n",
    "from utils.utils import decode_mask, decode_image, visualize\n",
    "\n",
    "from data.BKAIDataset import BKAIDataset\n",
    "from data.BalancedBKAIDataset import BalancedBKAIDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate Sigle GPU\n",
      "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:GPU:0'], variable_device = '/job:localhost/replica:0/task:0/device:GPU:0'\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 1:\n",
    "    try:\n",
    "        print(\"Activate Multi GPU\")\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        print(\"Activate Sigle GPU\")\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/pervinco/BKAI_MetaPolyp/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_dir = config[\"data_dir\"]\n",
    "image_dir = f\"{data_dir}/train\"\n",
    "mask_dir = f\"{data_dir}/train_mask\"\n",
    "gt_dir = f\"{data_dir}/train_gt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = sorted(glob(f\"{image_dir}/*\"))\n",
    "mask_files = sorted(glob(f\"{mask_dir}/*\"))\n",
    "gt_files = sorted(glob(f\"{gt_dir}/*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_distribution(mask_files, num_classes):\n",
    "    distribution = np.zeros(num_classes, dtype=np.int32)\n",
    "\n",
    "    for mask_file in mask_files:\n",
    "        mask = cv2.imread(mask_file)\n",
    "        # mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.resize(mask, (256, 256))\n",
    "        mask = encode_mask(mask)\n",
    "        \n",
    "        for class_id in range(num_classes):\n",
    "            distribution[class_id] += (mask == class_id).sum()\n",
    "\n",
    "    return distribution\n",
    "\n",
    "\n",
    "def plot_class_distribution(distribution, class_names=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if class_names:\n",
    "        plt.bar(class_names, distribution)\n",
    "    else:\n",
    "        plt.bar(np.arange(len(distribution)), distribution)\n",
    "\n",
    "    plt.ylabel('Number of Pixels')\n",
    "    plt.xlabel('Class')\n",
    "    plt.title('Class Distribution in Semantic Segmentation')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_batch_distribution(dataloader):    \n",
    "    if not os.path.isdir(\"./images\"):\n",
    "        os.makedirs(\"./images\")\n",
    "\n",
    "    for i, (images, masks) in enumerate(dataloader):\n",
    "        if i == 5:\n",
    "            break\n",
    "\n",
    "        print(i, images.shape, masks.shape)\n",
    "\n",
    "        distribution = np.zeros(config[\"num_classes\"], dtype=np.int32)\n",
    "        for j, (image, mask) in enumerate(zip(images, masks)):\n",
    "            image = image.numpy()\n",
    "            image = decode_image(image)\n",
    "            image = image.astype(np.uint8)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            prob_mask = np.argmax(mask, -1)\n",
    "            for class_id in range(config[\"num_classes\"]):\n",
    "                distribution[class_id] += (prob_mask == class_id).sum()\n",
    "\n",
    "            decoded_mask = decode_mask(prob_mask)\n",
    "            decoded_mask = decoded_mask.astype(np.uint8)\n",
    "            decoded_mask = cv2.cvtColor(decoded_mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            overlay = cv2.addWeighted(image, 0.7, decoded_mask, 0.3, 0)\n",
    "            result = np.hstack((image, decoded_mask, overlay))\n",
    "\n",
    "            cv2.imwrite(f\"./images/batch{i}_no{j}.png\", result)\n",
    "\n",
    "        print(distribution,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = image_files[0]\n",
    "# mask = mask_files[0]\n",
    "\n",
    "# image = cv2.imread(image)\n",
    "# mask = cv2.imread(mask)\n",
    "\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "# visualize([image], [mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = config[\"img_size\"] - 76\n",
    "\n",
    "# test_transform = A.Compose([\n",
    "#     # A.OneOf([A.RandomResizedCrop(height=size, width=size, p=0.5),\n",
    "#     #          A.CenterCrop(height=size, width=size, p=0.5)\n",
    "#     # ], p=1),\n",
    "#     A.RandomResizedCrop(height=size, width=size, p=1),\n",
    "#     # A.PadIfNeeded(p=1.0, min_height=config[\"img_size\"], min_width=config[\"img_size\"], pad_height_divisor=None, pad_width_divisor=None, border_mode=0, value=(0, 0, 0), mask_value=None)\n",
    "# ])\n",
    "\n",
    "# transformed = test_transform(image=image, mask=mask)\n",
    "# transformed_image, transformed_mask = transformed[\"image\"], transformed[\"mask\"]\n",
    "# visualize([transformed_image], [transformed_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_dist = compute_class_distribution(gt_files, num_classes=3)\n",
    "# print(gt_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_pixels = np.sum(gt_dist)\n",
    "# class_weights = total_pixels / (len(gt_dist) * gt_dist)\n",
    "# print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_class_weights = class_weights / np.sum(class_weights)\n",
    "# print(normalized_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = compute_class_distribution(mask_files, num_classes=3)\n",
    "# print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[966230  35584  46762] \n",
      "\n",
      "1 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[977310  22695  48571] \n",
      "\n",
      "2 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[980971  25792  41813] \n",
      "\n",
      "3 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[954942  26641  66993] \n",
      "\n",
      "4 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[992992  23993  31591] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = BalancedBKAIDataset(config, split=\"train\")\n",
    "print(len(dataset))\n",
    "\n",
    "dataloader = tf.data.Dataset.from_generator(lambda: dataset, \n",
    "                                            output_signature=(tf.TensorSpec(shape=(None, config[\"img_size\"], config[\"img_size\"], 3), dtype=tf.float32),\n",
    "                                                              tf.TensorSpec(shape=(None, config[\"img_size\"], config[\"img_size\"], 3), dtype=tf.float32)))\n",
    "\n",
    "calculate_batch_distribution(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
