{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "sys.path.append(\"/home/pervinco/BKAI_MetaPolyp\")\n",
    "\n",
    "import cv2\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from data.batch_preprocess import *\n",
    "from utils.utils import decode_mask, decode_image, visualize\n",
    "\n",
    "from data.BKAIDataset import BKAIDataset\n",
    "from data.BalancedBKAIDataset import BalancedBKAIDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate Sigle GPU\n",
      "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:GPU:0'], variable_device = '/job:localhost/replica:0/task:0/device:GPU:0'\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 1:\n",
    "    try:\n",
    "        print(\"Activate Multi GPU\")\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        print(\"Activate Sigle GPU\")\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/pervinco/BKAI_MetaPolyp/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_dir = config[\"data_dir\"]\n",
    "image_dir = f\"{data_dir}/train\"\n",
    "mask_dir = f\"{data_dir}/train_mask\"\n",
    "gt_dir = f\"{data_dir}/train_gt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = sorted(glob(f\"{image_dir}/*\"))\n",
    "mask_files = sorted(glob(f\"{mask_dir}/*\"))\n",
    "gt_files = sorted(glob(f\"{gt_dir}/*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_distribution(mask_files, num_classes):\n",
    "    distribution = np.zeros(num_classes, dtype=np.int32)\n",
    "\n",
    "    for mask_file in mask_files:\n",
    "        mask = cv2.imread(mask_file)\n",
    "        # mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.resize(mask, (256, 256))\n",
    "        mask = encode_mask(mask)\n",
    "        \n",
    "        for class_id in range(num_classes):\n",
    "            distribution[class_id] += (mask == class_id).sum()\n",
    "\n",
    "    return distribution\n",
    "\n",
    "\n",
    "def plot_class_distribution(distribution, class_names=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if class_names:\n",
    "        plt.bar(class_names, distribution)\n",
    "    else:\n",
    "        plt.bar(np.arange(len(distribution)), distribution)\n",
    "\n",
    "    plt.ylabel('Number of Pixels')\n",
    "    plt.xlabel('Class')\n",
    "    plt.title('Class Distribution in Semantic Segmentation')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_batch_distribution(dataloader):    \n",
    "    if not os.path.isdir(\"./images\"):\n",
    "        os.makedirs(\"./images\")\n",
    "\n",
    "    for i, (images, masks) in enumerate(dataloader):\n",
    "        if i == 5:\n",
    "            break\n",
    "\n",
    "        print(i, images.shape, masks.shape)\n",
    "\n",
    "        distribution = np.zeros(config[\"num_classes\"], dtype=np.int32)\n",
    "        for j, (image, mask) in enumerate(zip(images, masks)):\n",
    "            image = image.numpy()\n",
    "            image = decode_image(image)\n",
    "            image = image.astype(np.uint8)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            prob_mask = np.argmax(mask, -1)\n",
    "            for class_id in range(config[\"num_classes\"]):\n",
    "                distribution[class_id] += (prob_mask == class_id).sum()\n",
    "\n",
    "            decoded_mask = decode_mask(prob_mask)\n",
    "            decoded_mask = decoded_mask.astype(np.uint8)\n",
    "            decoded_mask = cv2.cvtColor(decoded_mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            overlay = cv2.addWeighted(image, 0.7, decoded_mask, 0.3, 0)\n",
    "            result = np.hstack((image, decoded_mask, overlay))\n",
    "\n",
    "            cv2.imwrite(f\"./images/batch{i}_no{j}.png\", result)\n",
    "\n",
    "        print(distribution,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = image_files[0]\n",
    "# mask = mask_files[0]\n",
    "\n",
    "# image = cv2.imread(image)\n",
    "# mask = cv2.imread(mask)\n",
    "\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "# visualize([image], [mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = config[\"img_size\"] - 76\n",
    "\n",
    "# test_transform = A.Compose([\n",
    "#     # A.OneOf([A.RandomResizedCrop(height=size, width=size, p=0.5),\n",
    "#     #          A.CenterCrop(height=size, width=size, p=0.5)\n",
    "#     # ], p=1),\n",
    "#     A.RandomResizedCrop(height=size, width=size, p=1),\n",
    "#     # A.PadIfNeeded(p=1.0, min_height=config[\"img_size\"], min_width=config[\"img_size\"], pad_height_divisor=None, pad_width_divisor=None, border_mode=0, value=(0, 0, 0), mask_value=None)\n",
    "# ])\n",
    "\n",
    "# transformed = test_transform(image=image, mask=mask)\n",
    "# transformed_image, transformed_mask = transformed[\"image\"], transformed[\"mask\"]\n",
    "# visualize([transformed_image], [transformed_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62030888   446415  3058697]\n"
     ]
    }
   ],
   "source": [
    "gt_dist = compute_class_distribution(gt_files, num_classes=3)\n",
    "print(gt_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35216864 48.93503429  7.14203902]\n"
     ]
    }
   ],
   "source": [
    "total_pixels = np.sum(gt_dist)\n",
    "class_weights = total_pixels / (len(gt_dist) * gt_dist)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00624089 0.86719283 0.12656628]\n"
     ]
    }
   ],
   "source": [
    "normalized_class_weights = class_weights / np.sum(class_weights)\n",
    "print(normalized_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62030892   446414  3058694]\n"
     ]
    }
   ],
   "source": [
    "dist = compute_class_distribution(mask_files, num_classes=3)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = BKAIDataset(config=config, split=config[\"train\"])\n",
    "# train_dataloader = tf.data.Dataset.from_generator(lambda: train_dataset, \n",
    "#                                                   output_signature=(tf.TensorSpec(shape=(None, config[\"img_size\"], config[\"img_size\"], 3), dtype=tf.float32),\n",
    "#                                                                     tf.TensorSpec(shape=(None, config[\"img_size\"], config[\"img_size\"], 3), dtype=tf.float32)))\n",
    "\n",
    "# calculate_batch_distribution(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "0 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[960549  49787  38240] \n",
      "\n",
      "1 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[965276  39112  44188] \n",
      "\n",
      "2 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[925236  37367  85973] \n",
      "\n",
      "3 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[991556  36316  20704] \n",
      "\n",
      "4 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[992334  27987  28255] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = BalancedBKAIDataset(config, split=\"train\")\n",
    "print(len(dataset))\n",
    "\n",
    "dataloader = tf.data.Dataset.from_generator(lambda: dataset, \n",
    "                                            output_signature=(tf.TensorSpec(shape=(None, config[\"img_size\"], config[\"img_size\"], 3), dtype=tf.float32),\n",
    "                                                              tf.TensorSpec(shape=(None, config[\"img_size\"], config[\"img_size\"], 3), dtype=tf.float32)))\n",
    "\n",
    "calculate_batch_distribution(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
