{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "sys.path.append(\"/home/pervinco/BKAI_MetaPolyp\")\n",
    "\n",
    "import cv2\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from data.batch_preprocess import *\n",
    "from utils.utils import decode_mask\n",
    "from data.batch_preprocess import encode_mask\n",
    "from data.BKAIDataset import BKAIDataset\n",
    "from data.BalancedBKAIDataset import BalancedBKAIDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/pervinco/BKAI_MetaPolyp/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_dir = config[\"data_dir\"]\n",
    "image_dir = f\"{data_dir}/train\"\n",
    "mask_dir = f\"{data_dir}/train_mask\"\n",
    "gt_dir = f\"{data_dir}/train_gt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = sorted(glob(f\"{image_dir}/*\"))\n",
    "mask_files = sorted(glob(f\"{mask_dir}/*\"))\n",
    "gt_files = sorted(glob(f\"{gt_dir}/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_distribution(mask_files, num_classes):\n",
    "    distribution = np.zeros(num_classes, dtype=np.int32)\n",
    "\n",
    "    for mask_file in mask_files:\n",
    "        mask = cv2.imread(mask_file)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.resize(mask, (256, 256))\n",
    "        mask = encode_mask(mask)\n",
    "        \n",
    "        for class_id in range(num_classes):\n",
    "            distribution[class_id] += (mask == class_id).sum()\n",
    "\n",
    "    return distribution\n",
    "\n",
    "\n",
    "def plot_class_distribution(distribution, class_names=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if class_names:\n",
    "        plt.bar(class_names, distribution)\n",
    "    else:\n",
    "        plt.bar(np.arange(len(distribution)), distribution)\n",
    "\n",
    "    plt.ylabel('Number of Pixels')\n",
    "    plt.xlabel('Class')\n",
    "    plt.title('Class Distribution in Semantic Segmentation')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_batch_distribution(dataloader):    \n",
    "    if not os.path.isdir(\"./images\"):\n",
    "        os.makedirs(\"./images\")\n",
    "\n",
    "    for i, (images, masks) in enumerate(dataloader):\n",
    "        print(i, images.shape, masks.shape)\n",
    "        if i == 5:\n",
    "            break\n",
    "\n",
    "        distribution = np.zeros(config[\"num_classes\"], dtype=np.int32)\n",
    "        for j, (image, mask) in enumerate(zip(images, masks)):\n",
    "            image = image.numpy()\n",
    "            image = (1 + image) * 127.5\n",
    "            image = image.astype(np.uint8)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            prob_mask = np.argmax(mask, -1)\n",
    "            for class_id in range(config[\"num_classes\"]):\n",
    "                distribution[class_id] += (prob_mask == class_id).sum()\n",
    "\n",
    "            decoded_mask = decode_mask(prob_mask)\n",
    "            decoded_mask = decoded_mask.astype(np.uint8)\n",
    "            decoded_mask = cv2.cvtColor(decoded_mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            overlay = cv2.addWeighted(image, 0.7, decoded_mask, 0.3, 0)\n",
    "\n",
    "            cv2.imwrite(f\"./images/batch{i}_no{j}.png\", overlay)\n",
    "\n",
    "        print(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62063243   437708  3035049]\n"
     ]
    }
   ],
   "source": [
    "gt_dist = compute_class_distribution(gt_files, num_classes=3)\n",
    "print(gt_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62063154   437709  3035137]\n"
     ]
    }
   ],
   "source": [
    "dist = compute_class_distribution(mask_files, num_classes=3)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = BKAIDataset(config=config, split=config[\"train\"])\n",
    "# train_dataloader = tf.data.Dataset.from_generator(lambda: train_dataset, \n",
    "#                                                   output_signature=(tf.TensorSpec(shape=(None, config[\"img_size\"], config[\"img_size\"], 3), dtype=tf.float32),\n",
    "#                                                                     tf.TensorSpec(shape=(None, config[\"img_size\"], config[\"img_size\"], 3), dtype=tf.float32)))\n",
    "\n",
    "# calculate_batch_distribution(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "0 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[979363  30153  39060]\n",
      "1 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[997678  24980  25918]\n",
      "2 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[972574  45212  30790]\n",
      "3 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[961596  39313  47667]\n",
      "4 (16, 256, 256, 3) (16, 256, 256, 3)\n",
      "[975945  21000  51631]\n",
      "5 (16, 256, 256, 3) (16, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset = BalancedBKAIDataset(config, split=\"train\")\n",
    "print(len(dataset))\n",
    "\n",
    "dataloader = tf.data.Dataset.from_generator(lambda: dataset, \n",
    "                                            output_signature=(tf.TensorSpec(shape=(None, config[\"img_size\"], config[\"img_size\"], 3), dtype=tf.float32),\n",
    "                                                              tf.TensorSpec(shape=(None, config[\"img_size\"], config[\"img_size\"], 3), dtype=tf.float32)))\n",
    "\n",
    "calculate_batch_distribution(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
